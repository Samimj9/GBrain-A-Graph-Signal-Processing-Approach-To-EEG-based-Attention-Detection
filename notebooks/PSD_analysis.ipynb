{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd72664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Define your file paths ---\n",
    "attention_file_path = r'C:\\Users\\LENOVO\\OneDrive - City University\\Desktop\\Attention detection FYP\\S01\\S01_clean\\Att_S01_cleaned_raw2.fif'\n",
    "inattention_file_path = r'C:\\Users\\LENOVO\\OneDrive - City University\\Desktop\\Attention detection FYP\\S01\\S01_clean\\Inatt_S01_cleaned_raw2.fif'\n",
    "\n",
    "# --- 2. Load your EEG data from .fif files ---\n",
    "print(f\"Loading attention data from: {attention_file_path}\")\n",
    "raw_attention = mne.io.read_raw_fif(attention_file_path, preload=True, verbose=False)\n",
    "print(f\"Loading inattention data from: {inattention_file_path}\")\n",
    "raw_inattention = mne.io.read_raw_fif(inattention_file_path, preload=True, verbose=False)\n",
    "\n",
    "# Optional: Set common average reference if your data isn't referenced yet.\n",
    "# It's generally good practice for EEG.\n",
    "# raw_attention.set_eeg_reference('average', verbose=False)\n",
    "# raw_inattention.set_eeg_reference('average', verbose=False)\n",
    "\n",
    "# Check info for both raw objects (e.g., channel names, sampling frequency)\n",
    "print(\"\\nAttention Raw Info:\")\n",
    "print(raw_attention.info)\n",
    "print(\"\\nInattention Raw Info:\")\n",
    "print(raw_inattention.info)\n",
    "\n",
    "# --- 3. Define Epoching Parameters ---\n",
    "epoch_length_s = 5  # seconds\n",
    "overlap_percent = 0.90 # 90% overlap\n",
    "sfreq = raw_attention.info['sfreq']\n",
    "\n",
    "# Calculate step size based on overlap\n",
    "# For 90% overlap, step_size_s = epoch_length_s * (1 - 0.90) = 10 * 0.10 = 1 seconds\n",
    "step_size_s = epoch_length_s * (1 - overlap_percent)\n",
    "print(f\"\\nEpoch length: {epoch_length_s} s, Overlap: {overlap_percent*100}%, Step size: {step_size_s} s\")\n",
    "\n",
    "# --- 4. Create Epochs for Attention and Inattention ---\n",
    "# mne.make_fixed_length_epochs will create non-overlapping epochs by default if step is None\n",
    "# We specify 'overlap_percent' as the amount each epoch overlaps, relative to its length\n",
    "# OR, more explicitly, we can specify 'overlap' in samples:\n",
    "# overlap_samples = int(epoch_length_s * sfreq * overlap_percent)\n",
    "# We need to set 'overlap' parameter in make_fixed_length_epochs if we want overlapping epochs.\n",
    "\n",
    "# Let's use the 'start' and 'stop' parameters for make_fixed_length_epochs\n",
    "# It's more straightforward to specify 'duration' and 'overlap' directly in seconds for newer MNE versions.\n",
    "\n",
    "# For MNE versions >= 1.0, the parameter 'overlap' is used for duration-based overlap.\n",
    "# For older versions, it might be 'tstep' for step duration.\n",
    "# We'll use the newer `overlap` parameter for clarity as you likely have a recent MNE.\n",
    "\n",
    "print(\"Creating epochs for Attention data...\")\n",
    "epochs_attention = mne.make_fixed_length_epochs(\n",
    "    raw_attention,\n",
    "    duration=epoch_length_s,\n",
    "    overlap=epoch_length_s * overlap_percent, # Overlap in seconds\n",
    "    preload=True,\n",
    "    verbose=False\n",
    ")\n",
    "print(f\"Number of Attention epochs: {len(epochs_attention)}\")\n",
    "\n",
    "print(\"Creating epochs for Inattention data...\")\n",
    "epochs_inattention = mne.make_fixed_length_epochs(\n",
    "    raw_inattention,\n",
    "    duration=epoch_length_s,\n",
    "    overlap=epoch_length_s * overlap_percent, # Overlap in seconds\n",
    "    preload=True,\n",
    "    verbose=False\n",
    ")\n",
    "print(f\"Number of Inattention epochs: {len(epochs_inattention)}\")\n",
    "\n",
    "# --- 5. Calculate PSD for Each Epoch and then Average ---\n",
    "# We calculate PSD for each epoch, and then average the resulting PSDs.\n",
    "# MNE's compute_psd on an Epochs object returns a Spectrum object.\n",
    "\n",
    "# Parameters for Welch's method for epochs\n",
    "# n_fft is typically set to the epoch length if you want maximum frequency resolution per epoch\n",
    "# or a bit smaller for smoothing. Since epochs are 20s, let's make n_fft reflect that.\n",
    "# Parameters for Welch's method for epochs\n",
    "# n_fft is typically set to the epoch length if you want maximum frequency resolution per epoch\n",
    "# or a bit smaller for smoothing. Since epochs are 20s, let's make n_fft reflect that.\n",
    "# Parameters for Welch's method for epochs\n",
    "# n_fft should be less than or equal to the number of samples in an epoch.\n",
    "# For 20s epochs, the number of samples per epoch is:\n",
    "samples_per_epoch = int(epoch_length_s * sfreq)\n",
    "\n",
    "# Choose n_fft to be the largest power of 2 that is <= samples_per_epoch\n",
    "n_fft = 2**int(np.log2(samples_per_epoch))\n",
    "\n",
    "print(f\"\\nEpoch length in samples: {samples_per_epoch}\")\n",
    "print(f\"Using n_fft: {n_fft} samples ({n_fft/sfreq:.2f} seconds) for PSD calculation per epoch\")\n",
    "\n",
    "# No overlap needed here for Welch's *within* an epoch, as we're already averaging over epochs.\n",
    "# The 'n_overlap' parameter here refers to the overlap of windows *within* each epoch for Welch's method.\n",
    "# It's common to use 50% overlap for Welch's internally for smoother PSD estimates.\n",
    "n_overlap_welch = int(0.5 * n_fft)\n",
    "window = 'hann'\n",
    "\n",
    "fmin = 1\n",
    "fmax = 40\n",
    "\n",
    "# Calculate PSD for Attention epochs\n",
    "print(f\"Calculating PSD for Attention epochs...\")\n",
    "# compute_psd on Epochs object returns an EpochsSpectrum object\n",
    "spectrum_att_epochs = epochs_attention.compute_psd(\n",
    "    method='welch',\n",
    "    fmin=fmin, fmax=fmax,\n",
    "    n_fft=n_fft, n_overlap=n_overlap_welch, # This is Welch's internal window overlap\n",
    "    picks='eeg',\n",
    "    average='mean', # Average across channels within each epoch\n",
    "    verbose=False\n",
    ")\n",
    "# Get the average PSD across all epochs for attention\n",
    "# spectrum_att_epochs.get_data() has shape (n_epochs, n_channels, n_frequencies)\n",
    "# So, we average across epochs (axis=0) and then convert to dB\n",
    "psds_att_avg_across_epochs, freqs = spectrum_att_epochs.average().get_data(return_freqs=True)\n",
    "psds_att_avg_across_epochs = 10 * np.log10(psds_att_avg_across_epochs) # Convert to dB\n",
    "\n",
    "# Calculate PSD for Inattention epochs\n",
    "print(f\"Calculating PSD for Inattention epochs...\")\n",
    "spectrum_inatt_epochs = epochs_inattention.compute_psd(\n",
    "    method='welch',\n",
    "    fmin=fmin, fmax=fmax,\n",
    "    n_fft=n_fft, n_overlap=n_overlap_welch,\n",
    "    picks='eeg',\n",
    "    average='mean',\n",
    "    verbose=False\n",
    ")\n",
    "psds_inatt_avg_across_epochs, _ = spectrum_inatt_epochs.average().get_data(return_freqs=True)\n",
    "psds_inatt_avg_across_epochs = 10 * np.log10(psds_inatt_avg_across_epochs) # Convert to dB\n",
    "\n",
    "# --- 6. Plotting the Average PSDs ---\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.plot(freqs, psds_att_avg_across_epochs.mean(axis=0), label='Attention (Mean across channels & epochs)', color='blue')\n",
    "plt.plot(freqs, psds_inatt_avg_across_epochs.mean(axis=0), label='Inattention (Mean across channels & epochs)', color='red')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Power Spectral Density (dB/Hz)')\n",
    "plt.title(f'Average PSD for Attention vs. Inattention (Subject S04 - 20s Epochs, 90% Overlap)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.axvspan(4, 8, color='gray', alpha=0.2, label='Theta Band')\n",
    "plt.axvspan(8, 12, color='orange', alpha=0.2, label='Alpha Band')\n",
    "plt.axvspan(12, 30, color='green', alpha=0.2, label='Beta Band')\n",
    "plt.xlim(fmin, fmax)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 7. Extracting Band Power (Features) ---\n",
    "# Define frequency bands\n",
    "bands = {\n",
    "    'delta': (0.5, 4),\n",
    "    'theta': (4, 8),\n",
    "    'alpha': (8, 12),\n",
    "    'beta': (12, 30),\n",
    "    'gamma': (30, 45)\n",
    "}\n",
    "\n",
    "# Calculate average power in each band for each condition\n",
    "band_powers_att = {}\n",
    "band_powers_inatt = {}\n",
    "\n",
    "print(\"\\n--- Calculating Band Powers (averaged across epochs) ---\")\n",
    "for band_name, (f_min_band, f_max_band) in bands.items():\n",
    "    idx_band = np.where((freqs >= f_min_band) & (freqs <= f_max_band))[0]\n",
    "\n",
    "    if len(idx_band) == 0:\n",
    "        print(f\"Warning: No frequencies found for {band_name} band ({f_min_band}-{f_max_band} Hz). Check fmin/fmax settings.\")\n",
    "        band_power_att = np.nan\n",
    "        band_power_inatt = np.nan\n",
    "    else:\n",
    "        # psds_att_avg_across_epochs has shape (n_channels, n_frequencies)\n",
    "        band_power_att = psds_att_avg_across_epochs[:, idx_band].mean()\n",
    "        band_power_inatt = psds_inatt_avg_across_epochs[:, idx_band].mean()\n",
    "\n",
    "    band_powers_att[band_name] = band_power_att\n",
    "    band_powers_inatt[band_name] = band_power_inatt # Corrected line\n",
    "\n",
    "print(\"\\nAverage Band Powers (dB/Hz):\")\n",
    "print(\"Attention:\", {k: f\"{v:.2f}\" for k, v in band_powers_att.items()})\n",
    "print(\"Inattention:\", {k: f\"{v:.2f}\" for k, v in band_powers_inatt.items()})\n",
    "\n",
    "# --- 8. Feature Engineering (Corrected Theta/Beta Ratio) ---\n",
    "theta_beta_ratio_att = np.nan\n",
    "theta_beta_ratio_inatt = np.nan\n",
    "\n",
    "# Attention Condition\n",
    "if 'theta' in band_powers_att and 'beta' in band_powers_att and \\\n",
    "   not np.isnan(band_powers_att['theta']) and not np.isnan(band_powers_att['beta']):\n",
    "\n",
    "    # Convert dB values back to linear power (microvolts^2/Hz)\n",
    "    theta_power_linear_att = 10**(band_powers_att['theta'] / 10)\n",
    "    beta_power_linear_att = 10**(band_powers_att['beta'] / 10)\n",
    "\n",
    "    # Calculate the ratio of linear powers\n",
    "    if beta_power_linear_att != 0: # Avoid division by zero\n",
    "        theta_beta_ratio_att = theta_power_linear_att / beta_power_linear_att\n",
    "    else:\n",
    "        print(\"Warning: Beta power for Attention is zero, cannot calculate Theta/Beta ratio.\")\n",
    "\n",
    "# Inattention Condition\n",
    "if 'theta' in band_powers_inatt and 'beta' in band_powers_inatt and \\\n",
    "   not np.isnan(band_powers_inatt['theta']) and not np.isnan(band_powers_inatt['beta']):\n",
    "\n",
    "    # Convert dB values back to linear power (microvolts^2/Hz)\n",
    "    theta_power_linear_inatt = 10**(band_powers_inatt['theta'] / 10)\n",
    "    beta_power_linear_inatt = 10**(band_powers_inatt['beta'] / 10)\n",
    "\n",
    "    # Calculate the ratio of linear powers\n",
    "    if beta_power_linear_inatt != 0: # Avoid division by zero\n",
    "        theta_beta_ratio_inatt = theta_power_linear_inatt / beta_power_linear_inatt\n",
    "    else:\n",
    "        print(\"Warning: Beta power for Inattention is zero, cannot calculate Theta/Beta ratio.\")\n",
    "\n",
    "\n",
    "print(f\"\\nTheta/Beta Ratio (Attention): {theta_beta_ratio_att:.2f}\")\n",
    "print(f\"Theta/Beta Ratio (Inattention): {theta_beta_ratio_inatt:.2f}\")\n",
    "\n",
    "print(\"\\nAnalysis Complete.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
